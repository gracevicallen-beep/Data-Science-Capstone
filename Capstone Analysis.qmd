---
title: "GAM Fraud Analysis"
subtitle: "Data Science Capstone Project"
author: "Grace Allen, Kesi Allen, Sonya Melton, Pingping Zhou"
date: "`r Sys.Date()`"
format: 
  html:
    code-fold: true       # Allows folding of code chunks
    self-contained: true  # Packages images and CSS in the HTML
output-dir: report1      # Folder where rendered HTML will go
bibliography: references.bib
csl: apa.csl 
execute: 
  warning: false
  message: false
css: styles.css 
course: "Capstone Projects in Data Science"
editor:
  markdown: 
    wrap: 72
---

## Slides

Slides: [slides.html](slides.html){target="_blank"} ( our slides html
link will go here)

## Introduction

Grace intro:

Generalized Additive Models (GAMs) build on traditional regression
methods by allowing more flexible and nonlinear relationships between
predictors and outcomes. Early work introduced GAMs as an extension of
generalized linear models that can capture complex patterns in data that
linear models often miss [@Hastie_1986]. Later research focused on
improving how GAMs are fit, making them more efficient and able to
handle larger datasets [@Detmer_2025]. These models have been widely
applied in different fields, such as ecology and biostatistics, where
they have been used to study species distributions [@Guisan_2002],
detect ecological thresholds [@Detmer_2025], and explore health outcomes
like alcohol consumption [@White_2020]. Together, these studies show
that GAMs are useful for uncovering hidden structure in data, but they
also highlight challenges such as the risk of overfitting, difficulty of
interpretation, and reliance on data quality.

More recent work has provided additional perspective on how GAMs operate
and when they are most reliable. A Bayesian approach has helped explain
how smoothing and variable selection can be understood as adding
structure to the model, while also giving clearer ways to measure
uncertainty [@Miller_2025]. At the same time, studies show that GAMs
perform best when data are rich and patterns are strong, while noisy or
sparse datasets can lead to misleading results [@Detmer_2025;
@Guisan_2002]. This makes GAMs well-suited as exploratory models that
highlight important nonlinear relationships, but less suited for drawing
final conclusions on their own. For our project on fraud detection,
these insights are valuable because they justify using GAMs to reveal
complex patterns in financial data, while reminding us to be careful
about issues like overfitting, noise, and interpretability.

Building on this foundation, our project applies GAMs to the Fraud
Detection Transactions Dataset from Kaggle [@Ashar_2024], a synthetic
but realistic dataset designed to simulate patterns of financial fraud.
Using RStudio and the mgcv package, we will conduct a series of GAM
analyses to identify which variables within the dataset serve as
significant indicators of fraud. This approach allows us to explore GAM
methodology in practice, evaluating both model performance and
interpretability while gaining hands-on experience with smoothing,
variable selection, and visualization techniques in a real-world-style
dataset.

Pingping intro:

Fraud detection has become increasingly reliant on advanced statistical
and machine learning approaches due to the complexity and evolving
nature of fraudulent behaviors. Among these approaches, Generalized
Additive Models (GAMs) offer a strong balance between predictive
flexibility and interpretability, making them particularly valuable in
domains where explainability is critical, such as finance, auditing,
healthcare, and cybersecurity.

Recent studies highlight both the strengths and limitations of GAMs in
fraud detection. For example, @Tragouda_2024 demonstrated the
effectiveness of GAMs in detecting bank cheque fraud, showing that while
uneven data and shifting fraud patterns reduced precision (5.6%), GAMs
maintained high recall (77.8%) and provided regulator-friendly
explanations. Similarly, @Miller_2025 applied GAMs to fraudulent
financial statements, showing that combining GAMs with models like
random forests can uncover irregular revenue patterns and provide
auditors with interpretable visualizations. In healthcare,
@Brossart_2015 used GAMs to identify fraudulent Medicare billing, where
their transparency built auditor trust, though they were less adaptive
to emerging fraud patterns.

Other interpretable methods, such as regularized generalized linear
models (Ridge, Lasso, and ElasticNet), have also proven effective in
fraud detection. @Hanagandi_2023 applied these models to highly
imbalanced credit card fraud datasets, achieving strong performance (up
to 98.2% accuracy with Ridge regression) and showing that careful data
preparation is crucial for real-time detection.

Beyond traditional GAMs, newer extensions demonstrate how fraud
detection can benefit from graph-based modeling. @Chang_2022 introduced
Graph Neural Additive Networks (GNANs), which extend GAMs to
graph-structured data such as transactions or social networks. GNANs
maintain interpretability while capturing complex relational patterns,
achieving 84.5% ROC-AUC in detecting banned or suspicious users.
Similarly, @Zhang_2025 explored telecom fraud detection using
graph-based frameworks, finding that GAMs effectively modeled sequential
features like call frequency and duration but were outperformed by graph
neural networks (GNNs) in capturing complex network interactions. These
findings suggest that while GAMs remain valuable for interpretable,
regulator-friendly fraud detection, newer graph-based models offer
improved performance when modeling intricate, interconnected data.

Sonya intro:

Generalized Additive Models (GAMs) are a class of interpretable
statistical models that provide a flexible approach to modeling
nonlinear relationships between predictors and an outcome variable.
Rather than assuming linear effects across all inputs, GAMs allow each
predictor to contribute to the response through its own smooth,
data-driven function. This additive yet flexible structure supports a
balance between accuracy and interpretability, making GAMs particularly
valuable in high-stakes domains such as financial fraud detection. In
banking applications, the ability to understand and visualize how
individual factors, such as transaction amount, time of day, or device
type, influence the likelihood of fraudulent behavior is critical for
compliance, risk mitigation, and transparency.

This project applies GAMs and related interpretable models to the Fraud
Detection Transactions Dataset from Kaggle [@Ashar_2024], a synthetic
but realistic dataset designed to simulate patterns of financial fraud.
The dataset includes thousands of transaction records, each labeled as
either fraudulent or legitimate. Key predictors include:

-   amount: the value of the transaction

-   type: transaction category (e.g., payment, transfer)

-   oldbalanceOrg and newbalanceOrig: account balances before and after
    the transaction

-   step: the hour of the transaction in a rolling window

-   isFlaggedFraud: whether a transaction was flagged by the internal
    system

GAMs are implemented using the mgcv package in R, where each variable's
effect is modeled as a smooth function via splines. For example, fitting
the model with mgcv::gam(isFraud \~ s(amount) + s(step) +
s(oldbalanceOrg), data = fraud_data, family = binomial) allows each
predictor’s nonlinear impact on fraud probability to be interpreted
individually using visualization tools such as plot.gam(). This
methodology closely aligns with the structure of Neural Additive Models
(NAMs), which assign separate subnetworks to each feature for
interpretability [@Agarwal_2021], as well as other modern GAM-based
approaches like Explainable Boosting Machines (EBMs) and GAMformer,
which aim to improve model scalability and robustness in complex
domains. In sum, GAMs provide a transparent, effective, and
well-supported framework for detecting fraudulent financial activity,
particularly when feature contributions need to be clearly explained and
trusted.

Kesi intro:

### Literature Review

Fraud detection has become increasingly reliant on advanced statistical
and machine learning approaches due to the complexity and evolving
nature of fraudulent behaviors. Among these approaches, Generalized
Additive Models (GAMs) provide a balance between predictive flexibility
and interpretability, making them especially suitable for domains where
explainability is critical, such as finance, auditing, and
cybersecurity.

1.  @Tragouda_2024 highlight GAMs’ ability to balance interpretability
    and predictive performance in fraud detection, such as bank cheque
    fraud. While challenges like uneven data and changing fraud patterns
    reduce precision (5.6%) but maintain recall (77.8%), GAMs provide
    clear explanations for regulators. Combining GAMs with other models
    can enhance accuracy while keeping results interpretable for legal
    and ethical oversight.
2.  @Miller_2025 investigates GAMs for identifying fraudulent financial
    statements, often hidden in complex accounting data. GAMs, combined
    with models like random forests, detect irregular revenue patterns
    and generate interpretable visualizations for auditors. Although
    effective, GAMs may miss sophisticated frauds involving multiple
    interacting factors. They provide a strong balance of accuracy and
    clarity for early detection of financial fraud.
3.  @Hanagandi_2023 explore regularized generalized linear models,
    including Ridge, Lasso, and ElasticNet, for detecting credit card
    fraud in highly imbalanced datasets (0.17% fraud cases). These
    models, similar to GAMs, capture complex transaction patterns while
    remaining interpretable. Ridge regression achieved high accuracy (up
    to 98.2%). The study highlights that careful data preparation is
    crucial for effective real-time fraud detection in banking
    environments.
4.  @Brossart_2015 discuss the application of GAMs to Medicare claims
    data for identifying fraudulent billing and overcharging. GAMs
    effectively detect unusual patterns and provide clear
    visualizations, which enhance auditor trust. While highly
    interpretable, they can be less adaptive to emerging fraud patterns
    compared to more complex models, but their transparency makes them
    valuable for healthcare fraud investigations.
5.  @Chang_2022 introduced Graph Neural Additive Networks (GNANs) as an
    extension of Generalized Additive Models (GAMs) for graph-structured
    data, enabling fraud detection in domains such as financial
    transaction networks and social platforms. GNANs combine graph
    neural networks with additive modeling, capturing complex relational
    patterns while maintaining interpretability through simple
    visualizations. Their approach achieved strong predictive
    performance, reaching 84.5% ROC-AUC in detecting banned or
    suspicious users, while also providing clear, auditable explanations
    that satisfy regulatory compliance.
6.  In telecom fraud detection, @Zhang_2025 introduced a graph-based
    framework that used Generalized Additive Models (GAMs) as a baseline
    for comparison. The study highlighted that GAMs are effective for
    modeling nonlinear patterns in sequential data, such as call
    frequency and duration, which are important for detecting fraudulent
    behavior. However, the results showed that GAMs were outperformed by
    graph neural networks (GNNs) in capturing complex network
    interactions, suggesting that GAMs are more appropriate for simpler
    fraud detection tasks where interpretability is prioritized over
    modeling intricate relationships (Zhang et al., 2025).

## Methods

Formally, a GAM can be expressed as:

$$ g(\mu) = \alpha + s_1(X_1) + s_2(X_2) + \dots + s_p(X_p) $$

where $g(\mu)$ is the link function (e.g., logit for binary outcomes or
identity for continuous outcomes), $\alpha$ is the intercept, and
$s_j(X_j)$ are smooth functions of the predictor variables $X_j$. This
structure allows each predictor to contribute a smoothed effect to the
model, capturing complex patterns in the data without obscuring the
individual influence of each variable. By balancing flexibility and
clarity, GAMs offer a practical alternative to fully nonparametric
methods, which can become computationally intensive and difficult to
interpret. The additive smooth functions $s_j(X_j)$ are at the heart of
GAMs, enabling the model to uncover nonlinear patterns while maintaining
interpretability for each predictor.

## Analysis and Results

### Data Exploration and Visualization

#### **Data set Description**

The Fraud Detection Transactions Dataset [@Ashar_2024] is a meticulously
crafted, synthetic dataset that replicates real-world financial
transaction patterns, making it a robust resource for building and
testing fraud detection models. Hosted on Kaggle, it is tailored for
binary classification tasks, with transactions labeled as fraudulent (1)
or non-fraudulent (0), and is designed to simulate the complexity of
financial systems while ensuring ethical data usage by avoiding real
user information. The dataset’s realistic design captures nuanced fraud
patterns, such as clustered fraudulent transactions, subtle anomalies,
or irregular user behaviors, providing a challenging yet representative
environment for machine learning applications in anomaly detection, risk
assessment, and fraud prevention.

The dataset’s synthetic nature replicates realistic fraud patterns,
including clustered fraudulent transactions, subtle anomalies, and
irregular user behaviors, while avoiding privacy concerns. Although the
exact number of records is unspecified, the data set is designed to be
sufficiently large and diverse, with a mix of typical transactions and
rare fraudulent events to address class imbalance — a common challenge
in fraud detection. Potential data quality issues, such as noisy data,
missing values, or outliers, reflect real-world complexities and require
preprocessing steps like data cleaning, categorical encoding, or
normalization. These challenges necessitate robust modeling techniques
to handle noise and ensure accurate predictions.

#### **Key Characteristics** 

The dataset simulates real-world financial transaction patterns,
capturing diverse user behaviors and transaction characteristics while
ensuring ethical data usage through its synthetic design. It is tailored
for binary classification tasks, with transactions labeled as fraudulent
(1) or non-fraudulent (0), and includes 21 features categorized as
follows:

-   **Size and Scope:** Contains thousands of individual transactions,
    each labeled as either fraudulent (1) or non-fraudulent (0).

-   **Features (21 total):**

    -   Numerical variables: transaction amounts, risk scores, balances,
        and other continuous measures.

    -   Categorical variables: transaction types (e.g., payment,
        transfer, withdrawal), device types, and merchant categories.

    -   Temporal variables: transaction time, day, and sequencing
        patterns that capture behavioral dynamics.

-   **Label Distribution:** Fraudulent transactions represent a small
    percentage of the data, reflecting the real-world class imbalance in
    fraud detection problems.

-   **Realism:** Although synthetic, the dataset mirrors real-world
    fraud scenarios by including behavioral signals, unusual spending
    patterns, and high-risk profiles.

**Flexibility:** Supports various modeling approaches, from
interpretable methods (e.g., GAMs, logistic regression) to
high-performance ensemble models (e.g., XGBoost).

### Modeling and Results

## Conclusion

## References
